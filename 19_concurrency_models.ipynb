{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19 Concurrency Models in Python\n",
    "Some notes, observations and questions along chapter 19.\n",
    "\n",
    "- concurrency is the broader term; it can involve parallelism\n",
    "\n",
    "- what makes concurrency difficult:\n",
    "\n",
    "    - keeping track of processes and threads: in order to get their return value, we\n",
    "      need to set up some communication channel (messages and queues)\n",
    "\n",
    "    - starting threads and processes is not for free: often this is navigated by making\n",
    "      each thread a \"worker\" that stands by and waits for tasks\n",
    "\n",
    "    - coroutines are cheaper to start, but they are often started by the asynchronous\n",
    "      framework, making them harder to keep track of\n",
    "\n",
    "### A Bit of Jargon\n",
    "\n",
    "##### Concurrency\n",
    "- ability to handle multiple tasks, one at a time or in parallel; requires OS scheduling\n",
    "\n",
    "##### Parallelism\n",
    "- ability to execute multiple computations at the same time; requires multi-core CPU, a\n",
    "  GPU, or several computers in a cluster\n",
    "\n",
    "##### Execution unit\n",
    "- objects that execute code concurrently, each with independent state and call stack; in\n",
    "  Python has three kinds: processes, threads, and coroutines\n",
    "\n",
    "##### Process\n",
    "- running instance with its own memory and slice of CPU time\n",
    "- communicate via pipes, sockets, or memory mapped files\n",
    "- Python objects must be serialized (converted) into raw bytes to pass from one process\n",
    "  to another (not every object is serializable)\n",
    "- can spawn subprocesses\n",
    "- OS scheduler schedules all the processes periodically\n",
    "\n",
    "##### Thread\n",
    "- execution unit within a single process\n",
    "- upon start each process uses one single thread: the main thread\n",
    "- threads within a process share the same memory space, which holds Python objects\n",
    "\n",
    "##### Coroutine\n",
    "- function that can suspend itself and resume later\n",
    "- *classic coroutines* are built from generator functions, and *native coroutines* are\n",
    "  defined with `async def`\n",
    "- run within a single thread under supervision of an *event loop*\n",
    "- coroutines support cooperative multitasking: each coroutine must explicitly cede\n",
    "  control with the `yield` or `await` keyword so that another may proceed concurrently\n",
    "\n",
    "##### Queue\n",
    "- data structure that lets us put and get items, usually in FIFO order: first in, first\n",
    "  out\n",
    "- allow separate execution units to exchange application data and control messages, such\n",
    "  as error codes and signals to terminate\n",
    "    - Copilot adds: Queues are not strictly necessary for communication between threads,\n",
    "      but highly recommended. While threads share memory and can technically communicate\n",
    "      via shared variables, this creates serious problems: **race conditions**\n",
    "      (unpredictable results when multiple threads read/write the same variable), and\n",
    "      the need for manual lock management around every shared access. Queues solve this\n",
    "      because they are **thread-safe** — they handle all locking internally. Critically,\n",
    "      queues are less about exchanging data objects (which threads can already access)\n",
    "      and more about **coordinating execution and safely signaling state changes**. This\n",
    "      is why `queue.Queue` exists: following the principle \"Don't communicate by sharing\n",
    "      memory; share memory by communicating.\"\n",
    "\n",
    "##### Lock\n",
    "- object that execution units can use to synchronize their actions and avoid corrupting\n",
    "  data\n",
    "- if several threads want to write to the same memory address, they need to wait until\n",
    "  they obtain the lock (other threads need to release it first)\n",
    "- for instance mutex (mutual exclusion lock)\n",
    "\n",
    "##### Contention\n",
    "- dispute (regulation?) about access to a limited access (like a lock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processes, Threads, and Python's Infamous GIL\n",
    "1. each instance of the Python interpreter is a process; additional processes can be\n",
    "   started with the `multiprocessing` and `concurrent.futures` libraries\n",
    "    - Each spawned process is a completely separate, independent operating\n",
    "      system process with its own CPython interpreter instance, memory space, and GIL.\n",
    "\n",
    "      You're correct that they're separate CPython sessions. They're not \"aligned\" with\n",
    "      the main process — they're genuinely separate executables running concurrently or\n",
    "      in parallel. The main process communicates with them via inter-process\n",
    "      communication (IPC) like `multiprocessing.Queue`, pipes, or sockets. On a\n",
    "      multi-core system, these processes can run truly in parallel (unlike threads,\n",
    "      which are GIL-limited). On a single-core system, the OS scheduler time-slices\n",
    "      between them. If you need to distribute processes across machines, you can use\n",
    "      libraries like `multiprocessing` with remote managers or dedicated frameworks like\n",
    "      `dask`.\n",
    "\n",
    "2. the Python interpreter uses a single thread to run the user's program and the memory\n",
    "   garbage collector; but we can start additional threads using the `threading` or the\n",
    "   `concurrent.futures` module\n",
    "    - remark: Really?! I thought garbage collection was done in a different thread or\n",
    "      process; but seems it is not.\n",
    "\n",
    "3. access to object reference counts and other internal interpreter state is controlled\n",
    "   by a lock, the Global Interpreter Lock (GIL); Only one Python thread can hold the GIL\n",
    "   at any time; meaning only one thread can execute Python code at any time, regardless\n",
    "   of the number of CPU cores\n",
    "    - GIL is existing in CPython and in PyPy, but not in Jython or in IronPython (but\n",
    "      those two are lagging behind anyways)\n",
    "    - question: Why do they point out write access of different threads to object\n",
    "      reference counts so prominently here? I would imagine that's trivial because it's\n",
    "      only a counter. I Imagine that the write access to living objects is much more\n",
    "      complex and also needs to be protected by locks.\n",
    "\n",
    "4. the GIL is released every 5 ms by default to prevent any thread to hold it too long\n",
    "\n",
    "5. several build-in functions (for instance those making a syscall) and some numpy and\n",
    "   scipy code can release the GIL, too\n",
    "\n",
    "6. touching with the C part of Python (as numpy does), we can write GIL-free threads\n",
    "\n",
    "7. network programming or programs heavily relying on I/O, will have no efficiency\n",
    "   problem with Python GIL\n",
    "\n",
    "8. contention over the GIL however slows down CPU-intense tasks \n",
    "\n",
    "#### Python's tools to work around the GIL\n",
    "\n",
    "- `threading` module lets us create multiple threads that can release the GIL during I/O operations (like network requests, file reads)\n",
    "- `multiprocessing` module avoids the GIL entirely by using separate processes, each with their own GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Concurrent Hello World\n",
    "\n",
    "These examples show multithreading, multiprocessing and asynch coroutines in a function\n",
    "that blocks for 3 seconds while displaying a spinner in the terminal to let the user\n",
    "know that the program is “thinking” and not stalled:\n",
    "    - each character in the string \"\\|/-\" in the same screen position\n",
    "    - when the slow computation finishes, the line with the spinner is cleared and the result is shown: Answer: 42\n",
    "\n",
    "### Spinner with Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Thread(Thread-20 (spin), initial)>\n",
      "Answer: 42  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "from threading import Thread, Event\n",
    "\n",
    "def spin(msg, done):\n",
    "    \"\"\"Run in the additional thread.\"\"\"\n",
    "    # the `done` param is an instance of `threading.Event`\n",
    "    for char in itertools.cycle(r'\\|/-'): # itertools.cycle creates an infinite loop\n",
    "        status = f'\\r{char} {msg}' # the ASCII '\\r' is a return character: returns the cursor\n",
    "        print(status, end='', flush=True) # prints status with spinning wheel to standard out\n",
    "        # this uses the Event.wait(timeout=None) method; done.set returns `False` while\n",
    "        # the event was not set by another thread and `True` when this event was set\n",
    "        # with `done.set()` by another thread:\n",
    "        if done.wait(.1): # the .1s timeout is the \"frame rate\"\n",
    "            break # exits the infinite loop\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='') # overwrites the status line with blank spaces in standard out\n",
    "\n",
    "def slow():\n",
    "    \"\"\"Run in the main thread.\"\"\"\n",
    "    time.sleep(3) \n",
    "    # time.sleep() blocks the calling thread but releases the GIL, allowing other Python threads to run; this\n",
    "    # is because it is not executing python code, but does a system call\n",
    "\n",
    "    return 42\n",
    "\n",
    "def supervisor():\n",
    "    \"\"\"Used to coordinate the threads.\"\"\"\n",
    "    done = Event()\n",
    "    spinner = Thread(target=spin, args=('thinking!', done)) # provide function as the `target` keyword argument, and arguments to the target\n",
    "    print(f'spinner object: {spinner}') # returns \"initial\" as the status of the thread, it means it has not started\n",
    "    spinner.start() # can run meanwhile the main thread is blocked\n",
    "    result = slow() # blocks the main thread\n",
    "    done.set() # we call this here (instead of in slow); it can anyways only run afterwards; this terminates the loop inside the `spin` function\n",
    "    spinner.join() # wait until the spinner thread finishes and join it into main thread\n",
    "    return print(f'Answer: {result}')\n",
    "\n",
    "supervisor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `threading.Event` returns the flag `False` by default and only returns `True` after `Event.set()` was called\n",
    "- while the flag is `False`, if a thread calls `Event.wait()`, it is blocked indefinitely until another thread calls `Event.set()`, at which time `Event.wait()` returns `True`\n",
    "- `Event.wait(timeout)` returns `False` when the timeout expires (without the event being set)\n",
    "\n",
    "### Spinner with Processes\n",
    "\n",
    "- emulates the threading API, so easily adaptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Process name='Process-2' parent=250529 initial>\n",
      "            \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "from multiprocessing import Process, Event\n",
    "\n",
    "def spin(msg, done):\n",
    "    \"\"\"Run in the child process.\"\"\"\n",
    "    # the `done` param is an instance of `multiprocessing.synchronize.Event`\n",
    "    for char in itertools.cycle(r'\\|/-'): # itertools.cycle creates an infinite loop\n",
    "        status = f'\\r{char} {msg}' # the ASCII '\\r' is a return character: returns the cursor\n",
    "        print(status, end='', flush=True) # prints status with spinning wheel to standard out\n",
    "        # this uses the Event.wait(timeout=None) method; done.set returns `False` while\n",
    "        # the event was not set by another thread and `True` when this event was set\n",
    "        # with `done.set()` by another thread:\n",
    "        if done.wait(.1): # the .1s timeout is the \"frame rate\"\n",
    "            break # exits the infinite loop\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='') # overwrites the status line with blank spaces in standard out\n",
    "\n",
    "def slow():\n",
    "    \"\"\"Run in the main process.\"\"\"\n",
    "    time.sleep(3) \n",
    "\n",
    "    return 42\n",
    "def supervisor():\n",
    "    done = Event()\n",
    "    spinner = Process(target=spin, args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join() # waiting for sub-process, also even joins it into the main process (I would not have thought they were joinable)\n",
    "    return result\n",
    "\n",
    "supervisor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- when creating a `multiprocessing.Process` instance, a whole new Python interpreter is started as a child\n",
    "  process in the background\n",
    "- calling `.join()` on a sub-process does the following\n",
    "    - block parent process until child terminates (wow!)\n",
    "    - collect exit status of child process\n",
    "    - clean up OS resources\n",
    "    - **NOT** doing: read childs memory and merge it into parent's memory\n",
    "- in the example, memory is not shared; the only data that crosses the process boundary is the Event state\n",
    "\n",
    "### Spinner with Coroutines\n",
    "- in contrast to `multithreading` and `multiprocessing`, in asynch programming, it is not the job of OS\n",
    "  schedulers to allocate CPU time to drive threads and processes; instead, coroutines are driven by an\n",
    "  application-level event loop that manages a queue of pending coroutines\n",
    "- the event loop and the library coroutines and the user coroutines all execute in a single thread\n",
    "    - any time spent in a coroutine slows down the event loop—and all other coroutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     spinner\u001b[38;5;241m.\u001b[39mcancel() \u001b[38;5;66;03m# Task.cancel method raises a `CancelledError` exception inside the spin coroutine\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The only regular function in this programme. The others are coroutines.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupervisor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# `asyncio.run()` starts the event loop to drive the coroutine that will eventually set the other coroutines in motion. The main function will stay blocked until supervisor returns. The return value of supervisor will be the return value of asyncio.run.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/asyncio/runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug, loop_factory)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import itertools\n",
    "\n",
    "async def spin(msg):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, flush=True, end='')\n",
    "        try:\n",
    "            await asyncio.sleep(.1)\n",
    "        except asyncio.CancelledError: # for exiting the loop\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "async def slow():\n",
    "    await asyncio.sleep(3) # await `asyncio.sleep(.1)` instead of `time.sleep(.1)`, to pause without blocking other coroutines\n",
    "    return 42\n",
    "\n",
    "def main():\n",
    "    \"\"\"The only regular function in this programme. The others are coroutines.\"\"\"\n",
    "    result = asyncio.run(supervisor()) # `asyncio.run()` starts the event loop to drive the coroutine that will eventually set the other coroutines in motion. The main function will stay blocked until supervisor returns. The return value of supervisor will be the return value of asyncio.run.\n",
    "    print(f'Answer: {result}')\n",
    "\n",
    "async def supervisor():\n",
    "    spinner = asyncio.create_task(spin('thinking!')) # schedules the eventual execution of spin\n",
    "    print(f'spinner object: {spinner}')\n",
    "    result = await slow() # `await` keyword calls slow, blocking supervisor until slow returns\n",
    "    spinner.cancel() # Task.cancel method raises a `CancelledError` exception inside the spin coroutine\n",
    "    return result\n",
    "\n",
    "main()\n",
    "\n",
    "# The code doesn't run in jupyter notebook because `asyncio.run()` creates and runs its own event loop, but it\n",
    "# can't do that if one is already active. Jupyter notebooks have a built-in event loop running in the\n",
    "# background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Task pending name='Task-6' coro=<spin() running at /tmp/ipykernel_250529/3707794880.py:4>>\n",
      "            \r"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import itertools\n",
    "\n",
    "async def spin(msg):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, flush=True, end='')\n",
    "        try:\n",
    "            await asyncio.sleep(.1)\n",
    "        except asyncio.CancelledError: # for exiting the loop\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "async def slow():\n",
    "    await asyncio.sleep(3) # await `asyncio.sleep(.1)` instead of `time.sleep(.1)`, to pause without blocking other coroutines\n",
    "    return 42\n",
    "\n",
    "async def main(): # fix for running this in a jupyter notebook\n",
    "    \"\"\"The only regular function in this programme. The others are coroutines.\"\"\"\n",
    "    result = await supervisor() # fix for running this in a jupyter notebook\n",
    "\n",
    "async def supervisor():\n",
    "    spinner = asyncio.create_task(spin('thinking!')) # schedules the eventual execution of spin\n",
    "    print(f'spinner object: {spinner}')\n",
    "    result = await slow() # `await` keyword calls slow, blocking supervisor until slow returns\n",
    "    spinner.cancel() # Task.cancel method raises a `CancelledError` exception inside the spin coroutine\n",
    "    return result\n",
    "\n",
    "await main()\n",
    "\n",
    "# Runs, but doesn't return the answer to the ultimate question of life, the universe, and everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- skipping deeper understanding an a few parts of the book\n",
    "- I choose not to put the same effort into understanding `asyncio` for now, as I did for `multithreading` and\n",
    "  `multiprocessing` (since this is not my main focus now).\n",
    "\n",
    "## The Real Impact of the GIL\n",
    "- system calls or http requests (among others) release the GIL because they delegate work to the OS kernel or external services\n",
    "- the real impact of the GIL becomes visible, when we need to wait to run CPU intense work\n",
    "    - GPU does not block the GIL because the computations happen outside of python on the GPU hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def is_prime(n: int) -> bool:\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    root = math.isqrt(n)\n",
    "    for i in range(3, root + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "is_prime(5_000_111_000_222_021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quiz: \n",
    "What would happen to the spinner animation if we replaced `time.sleep(3)` with is_prime, assuming that n =\n",
    "5_000_111_000_222_021 and the function would take 3.3 seconds to run?\n",
    "\n",
    "##### My answer:\n",
    "- for multiprocessing: the `supervisor` function would take 3,3 seconds to finish, and the spinner spins with a framerate of 0.1 as before\n",
    "- for multithreading: the GIL cannot be released at Event.wait(.1) and the spinner cannot turn until the main thread has finished\n",
    "- for asyncrio I didn't bother thinking about this and I couldn't care less\n",
    "\n",
    "Let's try out if I was right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Process name='Process-9' parent=250529 initial>\n",
      "Answer: True\n"
     ]
    }
   ],
   "source": [
    "# multiprocessing\n",
    "\n",
    "import itertools\n",
    "from multiprocessing import Process, Event\n",
    "\n",
    "def spin(msg, done):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, end='', flush=True)\n",
    "        if done.wait(.1):\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "def slow():\n",
    "    return is_prime(5_000_111_000_222_021)\n",
    "\n",
    "def supervisor():\n",
    "    done = Event()\n",
    "    spinner = Process(target=spin, args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return print(f'Answer: {result}')\n",
    "\n",
    "supervisor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spinner object: <Thread(Thread-96 (spin), initial)>\n",
      "Answer: True\n"
     ]
    }
   ],
   "source": [
    "# multithreading:\n",
    "\n",
    "import itertools\n",
    "from threading import Thread, Event\n",
    "\n",
    "def spin(msg, done):\n",
    "    for char in itertools.cycle(r'\\|/-'):\n",
    "        status = f'\\r{char} {msg}'\n",
    "        print(status, end='', flush=True)\n",
    "        if done.wait(.1):\n",
    "            break\n",
    "    blanks = ' ' * len(status)\n",
    "    print(f'\\r{blanks}\\r', end='')\n",
    "\n",
    "def slow():\n",
    "    return is_prime(5_000_111_000_222_021)\n",
    "\n",
    "def supervisor():\n",
    "    done = Event()\n",
    "    spinner = Thread(target=spin, args=('thinking!', done))\n",
    "    print(f'spinner object: {spinner}')\n",
    "    spinner.start()\n",
    "    result = slow()\n",
    "    done.set()\n",
    "    spinner.join()\n",
    "    return print(f'Answer: {result}')\n",
    "\n",
    "supervisor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the spinner spins for `multithreading`; surprising and interesting\n",
    "\n",
    "    - in Fluent Python the reason is given by \"the spinner keeps spinning because Python suspends the running\n",
    "      thread every 5ms (by default), making the GIL available to other pending threads\"\n",
    "\n",
    "## A Homegrown Process Pool\n",
    "- build a process pool to solve the following task: for a sample of 20 integers in the range of $2$ to $10^{16} -1$, compute which of these numbers are prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 20 numbers sequentially:\n",
      "               2 P  0.000003s\n",
      "3333333333333333    0.000008s\n",
      "4444444444444444    0.000001s\n",
      "5555555555555555    0.000002s\n",
      "6666666666666666    0.000001s\n",
      " 142702110479723 P  0.481053s\n",
      "7777777777777777    0.000014s\n",
      " 299593572317531 P  0.701333s\n",
      "9999999999999999    0.000008s\n",
      "3333333333333301 P  2.300070s\n",
      "3333335652092209    2.140204s\n",
      "4444444488888889    2.432362s\n",
      "4444444444444423 P  2.563128s\n",
      "5555553133149889    2.869161s\n",
      "5555555555555503 P  3.040242s\n",
      "6666666666666719 P  3.244250s\n",
      "6666667141414921    3.019099s\n",
      "7777777536340681    3.491293s\n",
      "7777777777777753 P  3.615976s\n",
      "9999999999999917 P  3.966707s\n",
      "Total time: 33.87s\n"
     ]
    }
   ],
   "source": [
    "# sequential implementation\n",
    "\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "import numpy as np\n",
    "\n",
    "NUMBERS = np.array([\n",
    "    2,\n",
    "    3333333333333333,\n",
    "    4444444444444444,\n",
    "    5555555555555555,\n",
    "    6666666666666666,\n",
    "    142702110479723,\n",
    "    7777777777777777,\n",
    "    299593572317531,\n",
    "    9999999999999999,\n",
    "    3333333333333301,\n",
    "    3333335652092209,\n",
    "    4444444488888889,\n",
    "    4444444444444423,\n",
    "    5555553133149889,\n",
    "    5555555555555503,\n",
    "    6666666666666719,\n",
    "    6666667141414921,\n",
    "    7777777536340681,\n",
    "    7777777777777753,\n",
    "    9999999999999917,\n",
    "], dtype=np.int64)\n",
    "\n",
    "class Result(NamedTuple):\n",
    "    prime: bool\n",
    "    elapsed: float\n",
    "\n",
    "def check(n): \n",
    "    t0 = perf_counter()\n",
    "    prime = is_prime(n)\n",
    "    return Result(prime, perf_counter() - t0)\n",
    "\n",
    "def main():\n",
    "    print(f'Checking {len(NUMBERS)} numbers sequentially:')\n",
    "    t0 = perf_counter()\n",
    "    for n in NUMBERS: \n",
    "        prime, elapsed = check(n)\n",
    "        label = 'P' if prime else ' '\n",
    "        print(f'{n:16} {label} {elapsed:9.6f}s')\n",
    "\n",
    "    elapsed = perf_counter() - t0 \n",
    "    print(f'Total time: {elapsed:.2f}s')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sequential implementation, the sum of the individual elapsed times (per number)\n",
    "should be more or less equal to the total time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count() # number of cores I have available (the physical + the synthetic ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 20 numbers with 14 processes:\n",
      "               2  P  0.000020s\n",
      "3333333333333333     0.000014s\n",
      "4444444444444444     0.000001s\n",
      "5555555555555555     0.000002s\n",
      "6666666666666666     0.000000s\n",
      "7777777777777777     0.000027s\n",
      "9999999999999999     0.000031s\n",
      " 142702110479723  P  0.742066s\n",
      " 299593572317531  P  0.993666s\n",
      "4444444488888889     3.232901s\n",
      "3333335652092209     3.311197s\n",
      "5555553133149889     3.427850s\n",
      "3333333333333301  P  3.759253s\n",
      "4444444444444423  P  4.268846s\n",
      "7777777536340681     4.849366s\n",
      "6666667141414921     5.197400s\n",
      "7777777777777753  P  5.337896s\n",
      "6666666666666719  P  5.792911s\n",
      "9999999999999917  P  6.022133s\n",
      "5555555555555503  P  6.314585s\n",
      "20 checks in 6.36s\n"
     ]
    }
   ],
   "source": [
    "# multi worker approach\n",
    "\n",
    "import sys\n",
    "from time import perf_counter\n",
    "from typing import NamedTuple\n",
    "from multiprocessing import Process, SimpleQueue, cpu_count\n",
    "from multiprocessing import queues\n",
    "\n",
    "class PrimeResult(NamedTuple):\n",
    "    # need to put n into this class, because results don't come back in the same order\n",
    "    n: int\n",
    "    prime: bool\n",
    "    elapsed: float\n",
    "\n",
    "JobQueue = queues.SimpleQueue[int] # queue to send numbers to the running processes from the main process\n",
    "ResultQueue = queues.SimpleQueue[PrimeResult] # queue to collect the results on the main process\n",
    "\n",
    "def check(n):\n",
    "    t0 = perf_counter()\n",
    "    res = is_prime(n)\n",
    "    return PrimeResult(n, res, perf_counter() - t0)\n",
    "\n",
    "def worker(jobs, results):\n",
    "    \"\"\"Worker gets a queue with the numbers to be checked, and another to put results.\"\"\"\n",
    "    while n := jobs.get(): # keep looping while the value fetched from the queue is truthy\n",
    "        results.put(check(n)) # check if n is_prime and enqueue PrimeResult\n",
    "    results.put(PrimeResult(0, False, 0.0)) # send back a PrimeResult(0, False, 0.0) to let the main loop know that this worker is done\n",
    "\n",
    "def start_jobs(procs: int, jobs: JobQueue, results: ResultQueue): # procs is the number of processes that will compute the prime checks in parallel\n",
    "    for n in NUMBERS:\n",
    "        jobs.put(n) # enqueue the numbers to be checked in jobs\n",
    "    for _ in range(procs):\n",
    "        # fork a child process for each worker. Each child will run the loop inside its \n",
    "        # own instance of the worker function, until it fetches a 0 from the jobs queue\n",
    "        proc = Process(target=worker, args=(jobs, results)) \n",
    "        proc.start()\n",
    "        jobs.put(0) # 0 here is used as a signal for the worker to finish (often None is used for this)\n",
    "\n",
    "def main():\n",
    "    procs = cpu_count()\n",
    "    print(f'Checking {len(NUMBERS)} numbers with {procs} processes:')\n",
    "    t0 = perf_counter()\n",
    "    jobs: JobQueue = SimpleQueue()\n",
    "    results: ResultQueue = SimpleQueue()\n",
    "    start_jobs(procs, jobs, results) # start `proc` processes to consume `jobs` and post `results`\n",
    "    checked = report(procs, results) # retrieve the results and display them\n",
    "    elapsed = perf_counter() - t0\n",
    "    print(f'{checked} checks in {elapsed:.2f}s')\n",
    "\n",
    "def report(procs: int, results: ResultQueue):\n",
    "    checked = 0\n",
    "    procs_done = 0\n",
    "    while procs_done < procs:\n",
    "        n, prime, elapsed = results.get() # get results is available; blocks the main process until an item is available; it doesn’t return or break if the queue is empty\n",
    "        if n == 0: # if `n` is zero, then one process exited; increment the `procs_done` count\n",
    "            procs_done += 1\n",
    "        else: # otherwise, increment the checked count (to keep track of the numbers checked) and display the results\n",
    "            checked += 1\n",
    "            label = 'P' if prime else ' '\n",
    "            print(f'{n:16}  {label} {elapsed:9.6f}s')\n",
    "    return checked\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we delegate computing to threads or processes, our code does not call the worker\n",
    "function directly, so we can't simply get a return value. Instead, the worker is driven\n",
    "by the thread or process library, and it eventually produces a result that needs to be\n",
    "stored somewhere. Coordinating workers and collecting results are common uses of queues\n",
    "in concurrent programming—and also in distributed systems.\n",
    "\n",
    "Here, 0 serves as a sentinel value, also called a \"poison pill\". Often None is used\n",
    "instead. It tells the worker to stop the iteration over the queue. We should pick\n",
    "something that cannot not occur in the data stream.\n",
    "\n",
    "Calling `.get()` on a queue blocks until there is an item in the queue. It's also\n",
    "possible to make this nonblocking, or set a timeout.\n",
    "\n",
    "For the multi worker solution, the sum of the individual elapsed times is larger than\n",
    "the actual total number of time to run this code. Though there is some overhead in\n",
    "spinning up processes and in inter-process communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python in the Multicore World\n",
    "\n",
    "- developing Python with a GIL was a no-brainer back in 1990\n",
    "- makes interpreters easier and many libraries don't ever need to release the GIL\n",
    "- nowadays optimizing code mainly comes with multiprocessing solutions\n",
    "\n",
    "## Chapter Summary\n",
    "Only processes allow Python to benefit from multicore CPUs. Python’s GIL makes threads\n",
    "possibly worse than sequential code for heavy computations (because of context-switching\n",
    "overhead)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fluent_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
